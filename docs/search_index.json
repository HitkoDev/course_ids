[
["docker-container-platform.html", "Chapter 3 Docker container platform 3.1 Why Docker? 3.2 Setting up the environment 3.3 Short introduction to Docker 3.4 Further reading and references 3.5 Learning outcomes 3.6 Practice problems", " Chapter 3 Docker container platform To enable the portability and easier scalability of our applications, there is a need to provide some tools that can package together tho whole environment, needed by our applications, such as library dependencies or language runtime. Docker is a set of tools that use operating-system-level virtualization to develop and deliver software in packages called containers. The software that hosts the containers is called Docker Engine and was first started in 2013 by Docker, Inc. Docker producst are available both in community and enterprise editions. Docker containers are isolated from each other and as mentioned above, they bundle their own software, libraries and configuration files. If our application consists of multiple services, a container can communicate with each other through internal or external network configuation. All containers are run by a single (host) operating-system kernel and are thus more lightweight than virtual machines. They are instantiated from Docker images that specify their precise contents. Images are often created by combining and modifying existing standard images downloaded from public repositories (i.e. image registries). An instance of an image (i.e. container) thus contains configured networking, storage, logging, etc. Furthermore, Docker defines an abstraction for these machine-specific settings and the exact same Docker container can run without any changes on many different machines, with many different configurations. There exist also similar technologies like Docker, which may not be that well known or are used for different scenarios, such as Singularity, Nanobox or LXC. Another approach of bundling applications into separate environment is using virtual machines, where each virtual machine contains its own whole operating system. Most known such virtualization technologies are VMWare products or Virtualbox. A technology in between the both Worlds is Vagrant, which enables a user to script the whole environment but when running the app, Vagrant creates a separate virtual machine (e.g. using Virtualbox) and runs it. 3.1 Why Docker? Author of a Linux.com article (Noyes 2008) described Docker as follows: Docker is a tool that can package an application and its dependencies in a virtual container that can run on any Linux server. This helps enable flexibility and portability on where the application can run, whether on premises, public cloud, private cloud, bare metal, etc. Virtual machines and containers have similar resource isolation and allocation benefits, but containers virtualize the operating system comparing to virtual machines which virtualize hardware. Therefore, containers are more portable and efficient. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up much less space than virtual machines (container images are typically tens of MBs in size) can handle more applications and require fewer operating systems. Virtual machines as an abstraction of physical hardware turn one server into many servers. The hypervisor allows multiple virtual machines to run on a single machine. Each virtual machine contains a full copy of an operating system, the application, necessary binaries and libraries. All these takes GBs of data and therefore virtual machines require more disk space, physical resources and are slower to boot. The Figure below shows a comparison between multiple running Docker containers (left side) and multiple virtual machines (right side). Figure 3.1: Dockerized applications vs. VM-virtualized applications (image courtesy of docker.com). 3.2 Setting up the environment To install Docker on your machine, you need to download the appropriate Docker Engine Community distribution from the official download website. You may notice that there exist also Docker Machine installation package, which is a provisioning and installation software for Docker - you do not need it at this point as it helps you managing multiple remote Docker hosts. After the installation you can explore different setting in the installation. A part of the installation is also a tool called Kitematic, which provides a handy GUI to overview downloaded images, containers, volumes and their settings. You can use it as a side-tool to command-line commands we introduce below. To check your Docker installation, run docker info to view some status details. Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 18.09.2 Storage Driver: overlay2 ... If you experience some permission problems, you need to allow your user to work with docker. Follow the post-installation guidelines. Now we are ready to test the Docker installation by running command docker run hello-world. If you see a similat message to the below, you are ready to start. Unable to find image &#39;hello-world:latest&#39; locally latest: Pulling from library/hello-world 1b930d010525: Pull complete Digest: sha256:6540fc08ee6e6b7b63468dc3317e3303aae178cb8a45ed3123180328bcc1d20f Status: Downloaded newer image for hello-world:latest Hello from Docker! This message shows that your installation appears to be working correctly. ... 3.3 Short introduction to Docker 3.3.1 Basics A Docker container is a runtime instance of an image - that is, an image with state, or a user process. You can see a list of available images usinf the command docker image ls: REPOSITORY TAG IMAGE ID CREATED SIZE docker-app latest 4b727c80cf90 4 minutes ago 475MB application latest cd497ca7013b 19 hours ago 538MB database latest 428448bc5e2d 19 hours ago 373MB ubuntu 18.04 4c108a37151f 4 weeks ago 64.2MB mysql 5 a1aa4f76fab9 5 weeks ago 373MB hello-world latest fce289e99eb9 6 months ago 1.84kB A container is launched by running an image. An image is an executable package that includes everything needed to run an application - the code, a runtime, libraries, environment variables, and configuration files. We have seen the docker run command that takes image name as a parameter. Image name looks like of [username/]repository[:tag], where tag is latest by default. To see all the container on your machine, issue the command docker container ls --all (the parameter –all will list also stopped containers): CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f6a55e492493 docker-app &quot;/bin/sh -c &#39;python3…&quot; 14 seconds ago Up 13 seconds 0.0.0.0:8787-&gt;8787/tcp kind_blackwell 42b33bc532ab hello-world &quot;/hello&quot; 22 minutes ago Exited (0) 22 minutes ago unruffled_morse 3.3.2 Docker application example To better understand everything, let’s develop a simple web application and run it within a docker container (solution of this part is available in folder app_only in the GitHub repository). We have a simple Python web server implementation (server.py) from flask import Flask from flask import json from flask import request from flask import Response app = Flask(__name__) @app.route(&#39;/&#39;, methods=[&#39;GET&#39;]) def index(): content = open(&quot;index.html&quot;).read() return Response(content, mimetype=&quot;text/html&quot;) if __name__ == &#39;__main__&#39;: app.run(host=&#39;0.0.0.0&#39;, port=8787) and accompanying HTML web template (index.html) &lt;html&gt; &lt;head&gt; &lt;title&gt;..:: Sample application ::..&lt;/title&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css&quot; integrity=&quot;sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO&quot; crossorigin=&quot;anonymous&quot;&gt; &lt;script src=&quot;https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/js/bootstrap.min.js&quot; integrity=&quot;sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt; &lt;script src=&quot;https://code.jquery.com/jquery-3.4.1.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; $( document ).ready(function() { employees = [ {&quot;name&quot;: &quot;John Doe&quot;, &quot;hobbies&quot;: &quot;I like cycling, mountain biking and skiing!!!&quot;, &quot;role&quot;: &quot;Director of operations&quot;}, {&quot;name&quot;: &quot;Melanie Oesch&quot;, &quot;hobbies&quot;: &quot;As the best jodeling singer, the love of my life is singing all day long. I come from Switzerland and have achieved many prizes. Maybe I also visit your hometown and get to know you.&quot;, &quot;role&quot;: &quot;Chairman of kids programme&quot;}, {&quot;name&quot;: &quot;Vladimir Zookeeper&quot;, &quot;hobbies&quot;: &quot;Animals are the nicest and very polite creatures in our world. I have observed many species already and I have not found an animal that would harm me without a reason (in comparison to a human being). My dream is to play with animals every day.&quot;, &quot;role&quot;: &quot;Animal feeder&quot;} ]; function addEmployee(employee) { $(&quot;#personnelListing&quot;).append(` &lt;a href=&quot;#&quot; class=&quot;list-group-item list-group-item-action flex-column align-items-start&quot;&gt; &lt;div class=&quot;d-flex w-100 justify-content-between&quot;&gt; &lt;h5 class=&quot;mb-1&quot;&gt;${employee.name}&lt;/h5&gt; &lt;/div&gt; &lt;p class=&quot;mb-1&quot;&gt;${employee.hobbies}&lt;/p&gt; &lt;small&gt;${employee.role}&lt;/small&gt; &lt;/a&gt; `); } $.each(employees, function( index, employee ) { addEmployee(employee); }); function processForm() { employee = { &quot;name&quot;: $(&quot;#name&quot;).val(), &quot;hobbies&quot;: $(&quot;#hobbies&quot;).val(), &quot;role&quot;: $(&quot;#role&quot;).val() }; addEmployee(employee); $(&quot;#name&quot;).val(&quot;&quot;), $(&quot;#hobbies&quot;).val(&quot;&quot;), $(&quot;#role&quot;).val(&quot;&quot;) } // Fetch all the forms we want to apply custom Bootstrap validation styles to var forms = document.getElementsByClassName(&#39;needs-validation&#39;); // Loop over them and prevent submission var validation = Array.prototype.filter.call(forms, function(form) { form.addEventListener(&#39;submit&#39;, function(event) { event.preventDefault(); event.stopPropagation(); if (form.checkValidity() === true) { processForm(); form.classList.remove(&#39;was-validated&#39;); } else { form.classList.add(&#39;was-validated&#39;); } }, false); }); }); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div class=&quot;container&quot;&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-10&quot;&gt; &lt;h1&gt;Personnel listing&lt;/h1&gt; &lt;/div&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-10&quot;&gt; &lt;h2&gt;Add an employee&lt;/h2&gt; &lt;/div&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-10&quot;&gt; &lt;form id=&quot;newEmployeeForm&quot; class=&quot;needs-validation&quot; novalidate&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;name&quot;&gt;Name&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;name&quot; placeholder=&quot;Enter your name&quot; required&gt; &lt;div class=&quot;invalid-feedback&quot;&gt; Please provide a valid city. &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;hobbies&quot;&gt;Hobbies&lt;/label&gt; &lt;textarea rows=&quot;3&quot; class=&quot;form-control&quot; id=&quot;hobbies&quot; placeholder=&quot;Describe your hobbies&quot; required&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;div class=&quot;form-group&quot;&gt; &lt;label for=&quot;role&quot;&gt;Role&lt;/label&gt; &lt;input type=&quot;text&quot; class=&quot;form-control&quot; id=&quot;role&quot; placeholder=&quot;Role in the organization&quot; required&gt; &lt;/div&gt; &lt;button type=&quot;submit&quot; class=&quot;btn btn-primary&quot;&gt;Save&lt;/button&gt; &lt;/form&gt; &lt;/div&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-10&quot;&gt; &lt;h2&gt;Employees&lt;/h2&gt; &lt;/div&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;row&quot;&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;div class=&quot;col-10&quot;&gt; &lt;div class=&quot;list-group&quot; id=&quot;personnelListing&quot;&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=&quot;col-1&quot;&gt;&lt;/div&gt; &lt;/div&gt; &lt;/body&gt; &lt;/html&gt; To run the application above, install Flask library in your Python 3 environment and run the server as python server.py: * Serving Flask app &quot;server&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:8787/ (Press CTRL+C to quit) Your web application is now accessible at http://localhost:8787. It is a simple JS-based we page, where you can add new employees into a local JS list. 3.3.2.1 Dockerfiles To define a container and be able to create an image, we must write a special file, called Dockerfile. Dockerfile defines what goes on in the environment inside your container. Access to resources like networking interfaces and disk drives is virtualized inside this environment, which is isolated from the rest of your system, so you need to map ports to the outside world, and be specific about what files you want to “copy in” to that environment. After doing that, you can expect that the build of your application defined in this Dockerfile behaves exactly the same wherever it runs. Let’s create a file, named Dockerfile with the following content: # Use an official Ubuntu runtime as a parent image FROM ubuntu:18.04 # Set the current working directory to /work WORKDIR /work # Copy the current directory contents into the container at /work ADD ./ . # Install and configure your environment RUN apt-get update \\ &amp;&amp; apt-get install -y python3 python3-pip \\ &amp;&amp; pip3 install flask # Make port 8787 available to the world outside this container (i.e. docker world) EXPOSE 8787 # Run server.py when the container launches ENTRYPOINT python3 server.py A full list of Dockerfile commands is described at the official Dockerfile documentation. If there is a need to prepare some specifics in the environment, it can be tedious to manually write all the RUN commands and check whether the application runs as expected. We can therefore always directly run the parent image and enter it’s shell to manually prepare the environment. We then copy the working commands into a Dockerfile and build our image. To create a container from a specific image and access it’s shell, run the following command: docker run -it ubuntu:18.04 /bin/bash. 3.3.2.2 Adding everything together Now we have the files server.py, index.html and Dockerfile in the same folder. If we move to the same folder, we can build a Docker image named docker-app using the following command docker build -t docker-app .: Sending build context to Docker daemon 9.728kB Step 1/6 : FROM ubuntu:18.04 ---&gt; 4c108a37151f .... Successfully built 4b727c80cf90 Successfully tagged docker-app:latest Now the image is available in our Docker system (verify that using docker image command as we did above). To create a running container based on our image, run docker run -p 8787:8787 docker-app: * Serving Flask app &quot;server&quot; (lazy loading) * Environment: production WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. * Debug mode: off * Running on http://0.0.0.0:8787/ (Press CTRL+C to quit) With this command we also map host’s port 8787 to Docker container’s port 8787. For additional options of docker run command, see the official reference. Our web application is now accessible at the same address as before, but is now running in a Docker container, congratulations! Sometimes we would still like to directly access shell of a running Docker container and check something (another option would be to install an ssh server into container and map a port to the host). First we need to get the id of our container using command docker ps and then execute docker exec -it CONTAINER_ID /bin/bash. Now we are connected directly to the “machine” that hosts our web application. If our running application generates logs, we can easily access them using docker logs CONTAINER_ID. 3.3.3 Volumes By default all files created inside a container are stored on a writable container layer. The main points to notice here are: The data doesn’t persist when that container no longer exists, and it can be difficult to get the data out of the container if another process needs it. A container’s writable layer is tightly coupled to the host machine where the container is running. You can’t easily move the data somewhere else. Writing into a container’s writable layer requires a storage driver to manage the filesystem. The storage driver provides a union filesystem, using the Linux kernel. This extra abstraction reduces performance as compared to using data volumes, which write directly to the host filesystem. As a result, best practices are to always create containers read-only. Docker thus provides two solutions to store files, which are persisted also after the container removal - volumes and bind mounts. Volumes are the best way to persist data in Docker. Commands to manage Docker volumes start with docker volume (add –help parameter to list all options). After the volume is created, we can map it to a specific mount point when running the container (see docker run command reference for more). 3.3.4 Docker application example with multiple services When developing an application that consist of multiple services, we can also create one “fat” container hosting all the services. This is not the Docker best practice as therefore each service should be run within a separate Docker container. Let’s upgrade our web application and add database support to it (solution of this part is available in folder app_and_database in the GitHub repository). 3.3.4.1 Web application service Web application service is similar to the example above. The differences are installation of an additional mysql-connector-python library into the container (Dockerfile), implementation of REST calls to the backend (index.html) and server endpoints implementation (server.py). In the implementation we should notice the connection settings from the application to the database. As we said, both services will run separately in a Docker container, so we should provide a connection between them. When we run the services, we should name the containers and create a network among running services. Connection settings look like as follows: config = { &#39;user&#39;: &#39;root&#39;, &#39;password&#39;: &#39;BeReSeMi.DataScience&#39;, &#39;host&#39;: &#39;database&#39;, &#39;database&#39;: &#39;data_science&#39;, &#39;raise_on_warnings&#39;: False } We should notice the host setting and by default, port 3306 is used to connect to a MySQL database. In the MySQL container, that port will also needed to be exposed within the Dockerfile. Docker services can be connected using separate virtual networks and by default, bridge networks are created to interconnect running containers. For more sophisticated examples, see the official network setting guidelines. 3.3.4.2 Database service For the database service, we will use already created image, which is available from the public MySQL image repository (for more info on repositories, see section 3.3.4.4). Along with the image, there are also instructions of how to use it with the parameters, where to put initial script files, … to ease the deployment process without creating complicated Dockerfiles. In our case, the database dockerfile looks as follows: # Parent image FROM mysql:5 # Copying all files in curent dir to container ADD ./ /docker-entrypoint-initdb.d # Updating permissions for the copied files RUN /bin/bash -c &#39;chmod a+rx /docker-entrypoint-initdb.d/*&#39; We observe that only thing we did is just copying files into a special folder in the container (/docker-entrypoint-initdb.d) which was previously set as init folder, where all the .sql scripts are run at startup. To test our Dockerfile, we can also run it separately using the command (from the database folder) docker build -t docker-db . &amp;&amp; docker run -p 3306:3306 -e MYSQL_ROOT_PASSWORD=BeReSeMi docker-db. We set the database password of the root user using an environment variable, which can be used to connect to the database. Now we can connect to the database from the host machine - e.g. use MySQL Workbench and connection settings to localhost:3306. If everything is okay, a database named data_science should be created along with the employees table and few entries in it. 3.3.4.3 Docker compose Congratulations! Now you know how to create docker containers separately. We just need to glue them together and run them more easily. Docker compose is the easiest tool to help us out. Docker Compose is a tool for defining and running multi-container Docker applications. It uses YAML files to configure the application’s services and performs the creation and start-up process of all the containers with a single command. The docker-compose CLI utility allows you to run commands on multiple containers at once, for example, building images, scaling containers, running containers that were stopped, and more. The docker-compose.yml file is used to define an application’s services and includes various configuration options. Before continuing, stop all running containers and move to the app_and_database folder. First, let’s check the docker-compose.yml file: version: &#39;3.7&#39; services: database: image: database build: ./database command: --default-authentication-plugin=mysql_native_password restart: always environment: MYSQL_ROOT_PASSWORD: BeReSeMi.DataScience ports: - 3306:3306 volumes: - ds_databases:/var/lib/mysql networks: - dsnet application: image: application build: ./application depends_on: - database restart: always ports: - &quot;8787:8787&quot; networks: - dsnet networks: dsnet: driver: bridge volumes: ds_databases: In the docker-compose configuration we define two containers, one named database and other application. Parameter build defines the folder with an appropriate Dockerfile or directly an already built image name. Parameter restart instructs the container to automaticallt restart its service if is suddenly stopped (due to crash, error, …). Parameter depends_on created dependencies between containers, so the application container will be started after the database container is running (tip: be aware that this is based on the time when service is beginning to start, so if database script initialization takes long time, database service may be running later than the application service). With the volumes parameter we map a specific folder in the container to a named volume db_databases - this folder will contain the database data. We also define a network named dsnet with the bridge configuration and therefore both containers will be able to communicate with each other. To run the docker-compose configuration, run docker-compose up (for detached mode add parameter -d at the end). Both containers should be created and running - to verify, navigate to http://localhost:8787 and add some employees. Data should be persistent and stored into the database. To shut down the containers, press CTRL+C (or run docker-compose down if you started containers in a detached mode). 3.3.4.4 Image registries We have already mentioned that there exist already prepared images, which can be retried from the public repositories. Repositories can be public or private. Two main public registries are Docker Hub and Docker Cloud. Docker Hub is the default registry where Docker looks for images. Docker clients connect to Docker repositories to download (pull) images for use or upload (push) images that they have built. We have published the image of the first example in the repository szitnik/docker-ds-app (link). You can pull the image (docker pull command) or run it directly with the command: docker run -p 8787:8787 szitnik/docker-ds-app The functionality should be the same as with the image you created during this tutorial. To publish images to Docker Hub, you will need first to create account and then you will be able to publish your own images. Let’s say that you still have built image from the first example, named docker-app. You can push it to the Docker Hub using the following commands: # Provide credentials and login docker login # Tag your local image docker tag docker-app USERNAME/PUBLIC_IMAGE_NAME:TAG # Publish your image docker push USERNAME/PUBLIC_IMAGE_NAME:TAG If you do not define the tag, it will be latest by default. You can access your image via Web interface at https://hub.docker.com/r/USERNAME/PUBLIC_IMAGE_NAME*, where you can also add description, instructions, publish the Dockerfile* or connect its content to your Git repository. Now anybody can pull &amp; run your image using the same procedure as we did above. 3.4 Further reading and references Check the Docker official web page and the Docker tutorial. For more advanced topics get to know container orchestration solutions like Docker Swarm or Kubernetes. Docker in Action book teaches readers how to create, deploy, and manage applications hosted in Docker containers. The Docker Book is inteded for complete beginners offering 268 pages of demos and live tutorials. Docker Cookbook presents more advanced Docker techniques like mounting data across multiple servers, distributed containers, detailed monitoring, networking across multiple hosts, accessing Docker in the cloud and merging with other platforms like Kubernetes. 3.5 Learning outcomes Data science students should work towards obtaining the knowledge and the skills that enable them to: Use an existing Docker image. Package and application consisting of multiple services into one or more containers and manage them. Publish reproducive algorithms to Docker Hub. Use and extend existing public Docker images. 3.6 Practice problems Create a simple Python program or web application, write a Dockerfile to compile an image an publish it on Docker Hub. If you are more proficient with some other language, use a framework of your choice. Write a service, which needs multiple servers deployed and run everything using docker compose. Dockerize your Introduction to Data Science project and publish it to Docke Hub. Add instructions of how to use your image. References "]
]
